"""
æ¸¬è©¦ Gemini AI é©…å‹•çš„æ¨¡ç³Šæœå°‹åŠŸèƒ½
"""
import os
from dotenv import load_dotenv
from crawler import TechOrangeCrawler
import logging

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)

def test_ai_fuzzy_search():
    """æ¸¬è©¦ AI æ¨¡ç³Šæœå°‹åŠŸèƒ½"""
    print("ğŸ¤– æ¸¬è©¦ Gemini AI é©…å‹•çš„æ¨¡ç³Šæœå°‹åŠŸèƒ½...")
    
    # æª¢æŸ¥ API Key
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
        print("âŒ æœªæ‰¾åˆ° GEMINI_API_KEYï¼Œå°‡ä½¿ç”¨å‚³çµ±æ¨¡ç³Šæœå°‹")
    else:
        print("âœ… æ‰¾åˆ° GEMINI_API_KEYï¼Œå°‡ä½¿ç”¨ AI æ¨¡ç³Šæœå°‹")
    
    # åˆå§‹åŒ–çˆ¬èŸ²
    crawler = TechOrangeCrawler()
    
    # æ¸¬è©¦é—œéµå­—
    test_keywords = [
        "AI",
        "æ°¸çºŒ",
        "å…ƒå®‡å®™",
        "NFT",
        "é è·å·¥ä½œ"
    ]
    
    for keyword in test_keywords:
        print(f"\nğŸ” æ¸¬è©¦é—œéµå­—: '{keyword}'")
        print("=" * 60)
        
        try:
            # ç”Ÿæˆæ¨¡ç³Šé—œéµå­—
            fuzzy_keywords = crawler._generate_fuzzy_keywords(keyword)
            print(f"ğŸ“ ç”Ÿæˆçš„ç›¸é—œé—œéµå­—: {fuzzy_keywords}")
            
            # æ¨¡æ“¬æ¨™é¡ŒåŒ¹é…æ¸¬è©¦
            test_titles = [
                f"{keyword}æŠ€è¡“çªç ´",
                f"ä¼æ¥­å°å…¥{keyword}è§£æ±ºæ–¹æ¡ˆ",
                "ç§‘æŠ€è¶¨å‹¢èˆ‡å‰µæ–°æ‡‰ç”¨",
                f"{keyword}å¸‚å ´åˆ†æå ±å‘Š"
            ]
            
            print("ğŸ“Š åŒ¹é…åˆ†æ•¸æ¸¬è©¦:")
            for title in test_titles:
                score = crawler._calculate_match_score(
                    title.lower(), 
                    keyword.lower(), 
                    fuzzy_keywords
                )
                print(f"   '{title}' â†’ åˆ†æ•¸: {score}")
                
        except Exception as e:
            print(f"âŒ æ¸¬è©¦å¤±æ•—: {str(e)}")
        
        print()

def compare_search_methods():
    """æ¯”è¼ƒ AI æœå°‹èˆ‡å‚³çµ±æœå°‹çš„å·®ç•°"""
    print("\nğŸ”„ æ¯”è¼ƒ AI æœå°‹èˆ‡å‚³çµ±æœå°‹...")
    
    crawler = TechOrangeCrawler()
    test_keyword = "é‡‘èç§‘æŠ€"
    
    print(f"é—œéµå­—: {test_keyword}")
    print("-" * 40)
    
    # AI ç”Ÿæˆé—œéµå­—
    ai_keywords = crawler._generate_fuzzy_keywords(test_keyword)
    print(f"ğŸ¤– AI ç”Ÿæˆ: {ai_keywords}")
    
    # å‚³çµ±æ–¹æ³•é—œéµå­—
    traditional_keywords = crawler._generate_traditional_fuzzy_keywords(test_keyword)
    print(f"ğŸ“š å‚³çµ±æ–¹æ³•: {traditional_keywords}")
    
    # æ¯”è¼ƒè¦†è“‹ç¯„åœ
    ai_only = set(ai_keywords) - set(traditional_keywords)
    traditional_only = set(traditional_keywords) - set(ai_keywords)
    
    if ai_only:
        print(f"âœ¨ AI ç¨æœ‰é—œéµå­—: {list(ai_only)}")
    if traditional_only:
        print(f"ğŸ“– å‚³çµ±æ–¹æ³•ç¨æœ‰: {list(traditional_only)}")

if __name__ == "__main__":
    test_ai_fuzzy_search()
    compare_search_methods()
