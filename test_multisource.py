"""
æ¸¬è©¦å¤šä¾†æºçˆ¬èŸ²åŠŸèƒ½
"""
from crawler import MultiSourceTechCrawler
import logging

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)

def test_multisource_crawler():
    """æ¸¬è©¦å¤šä¾†æºçˆ¬èŸ²"""
    print("ğŸ” æ¸¬è©¦å¤šä¾†æºç§‘æŠ€æ–°èçˆ¬èŸ²...")
    
    # åˆå§‹åŒ–çˆ¬èŸ²
    crawler = MultiSourceTechCrawler()
    
    # æ¸¬è©¦é—œéµå­—
    test_keywords = ["AI", "5G", "å€å¡Šéˆ"]
    
    for keyword in test_keywords:
        print(f"\nğŸ“° æœå°‹é—œéµå­—: {keyword}")
        print("=" * 50)
        
        articles = crawler.fetch_articles(keyword, 2)
        
        if articles:
            print(f"âœ… æ‰¾åˆ° {len(articles)} ç¯‡æ–‡ç« :")
            for i, article in enumerate(articles, 1):
                print(f"\n{i}. æ¨™é¡Œ: {article.get('title', 'ç„¡æ¨™é¡Œ')}")
                print(f"   ä¾†æº: {article.get('source', 'æœªçŸ¥ä¾†æº')}")
                print(f"   ç¶²å€: {article.get('url', 'ç„¡ç¶²å€')}")
                print(f"   å…§å®¹é è¦½: {article.get('content', 'ç„¡å…§å®¹')[:100]}...")
        else:
            print(f"âŒ æ²’æœ‰æ‰¾åˆ°èˆ‡ '{keyword}' ç›¸é—œçš„æ–‡ç« ")
        
        print()

if __name__ == "__main__":
    test_multisource_crawler()
